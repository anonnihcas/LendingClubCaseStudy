{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn  as sns\n",
    "\n",
    "\n",
    "loan_file = pd.read_csv(\".\\\\loan\\\\loan.csv\")\n",
    "## 1. Problem Statement ##\n",
    "\n",
    "Problem to be solved: Identify patterns based on the columns which would be used to reject/deny loans, reduce the loan amount or charge higher interest rate.\n",
    "## 2. Data Provided ##\n",
    "\n",
    "The data shared is from a Consumer Finance company specializing in lending various types of loans. The data consist of 39717 rows spread across 111 columns. One of the columns indicates whether the loan is currently \n",
    "\n",
    "1. Ongoing\n",
    "2. Fully Paid - Loan Fully paid by the Consumer\n",
    "3. Charged Off - Consumer who has defaulted the loans and are marked for Collections by the Company.\n",
    "\n",
    "loan_file.head(5)\n",
    "loan_file.shape\n",
    "# 3. Data Cleanup. #\n",
    "\n",
    "#### 3.1 Identifying Null Columns ###\n",
    "\n",
    "Based on cursory glance of the data, there are several columns which seem to have null values in the data. The first step is to identify colums which have null values.\n",
    "type(loan_file.isnull().sum())\n",
    "\n",
    "filtered_series = loan_file.isnull().sum()[loan_file.isnull().sum() == 39717]\n",
    "print(filtered_series.shape)\n",
    "filtered_series.to_csv('cols_having_empty_header.csv',header=['Count of Row Values'],index=True)\n",
    "\n",
    "#### 3.2 Removing Null-valued columns ####\n",
    "\n",
    "There are over 54 columns which seem to have null values. The first step is to remove these columns as they do not contribute to analysis.\n",
    "Throughout the course of analysis,  a CSV file is generated to view the output and to assess the progress. \n",
    "loan_file.dropna(axis=1,how='all',inplace=True)\n",
    "loan_file.shape\n",
    "total_length = len(loan_file)\n",
    "\n",
    "# loan_file.columns[]\n",
    "print((loan_file.columns[(loan_file.isnull().sum()/total_length) > 0.75]).value_counts())\n",
    "print((loan_file.columns[(loan_file.isnull().sum()/total_length) > 0.50]).value_counts())\n",
    "print((loan_file.columns[(loan_file.isnull().sum()/total_length) > 0.25]).value_counts())\n",
    "\n",
    "loan_file.drop(columns=loan_file.columns[(loan_file.isnull().sum()/total_length) > 0.50],inplace=True)\n",
    "print(loan_file.shape)\n",
    "loan_file.to_csv(\".\\\\iteration_1.csv\")\n",
    "#### 3.3 Unique valued Columns ####\n",
    "\n",
    "There are several columns which have unique values - these do not contribute to any analaysis due to invariant nature of data. The next step is to identify the list of columns and delete them.\n",
    "unique_count_of_values = loan_file.nunique()\n",
    "list_of_unique_count_of_values = unique_count_of_values[unique_count_of_values == 1].index.tolist()\n",
    "\n",
    "print(list_of_unique_count_of_values)\n",
    "\n",
    "# loan_file.drop(columns=['pymnt_plan','url','desc','initial_list_status','collections_12_mths_ex_med','policy_code','application_type','acc_now_delinq','chargeoff_within_12_mths','delinq_amnt','tax_liens'],inplace=True)\n",
    "\n",
    "\n",
    "loan_file.drop(columns=list_of_unique_count_of_values,inplace=True)\n",
    "print(loan_file.shape)\n",
    "\n",
    "loan_file.to_csv(\".\\\\iteration_2.csv\")\n",
    "#### 3.4 Removal of additional columns. ####\n",
    "\n",
    "Upon visual analysis of columns, there are several columns which does not aid the analysis. Deleting rows which are descriptive and which does not contribute to identification.\n",
    "\n",
    "| Field Name | Remarks |\n",
    "| -------- | -------- |\n",
    "| member_id | We shall retain id for reference purpose. Assumption - member_id will be retrieved from id |\n",
    "| emp_title | Descriptive. Does not seem to contribute. |\n",
    "| emp_length | Descriptive. Does not seem to contribute. |\n",
    "| title | Descriptive. Does not seem to contribute. |\n",
    "| last_credit_pull_d | The most recent month LC pulled credit for this loan - Does not contribute towards analysis.. |\n",
    "| last_pymnt_amnt |  Last total payment amount received - Does not contribute towards analysis.|\n",
    "| last_pymnt_d | Last month payment was received - Does not contribute towards analysis. |\n",
    "| collection_recovery_fee | post charge off collection fee - Does not contribute towards analysis. |\n",
    "| earliest_cr_line | The month the borrower's earliest reported credit line was opened - Does not contribute towards analysis.|\n",
    "| addr_state | The state provided by the borrower in the loan application - All the states are allowed . |\n",
    "| Zip Code| The first 3 numbers of the zip code provided by the borrower in the loan application.  Removed to prevent redlining and bias from the model. |\n",
    "| issue_d |  The month which the loan was funded- Does not contribute towards analysis.|\n",
    "| funded_amnt |  The total amount committed to that loan at that point in time.|\n",
    "| funded_amnt_inv |  The total amount committed by investors for that loan at that point in time..|\n",
    "| verification_status |  Indicates if income was verified by LC, not verified, or if the income source was verified.|\n",
    "|url| URL for the LC page with listing data - Does not contribute to analysis|\n",
    "|desc| Loan description provided by the borrower - Does not contribute to analysis|\n",
    "|total_rec_late_fee|Late fees received to date - Does not contribute to analysis|\n",
    "|total_rec_prncp|Principal received to date - Does not contribute to analysis|\n",
    "|total_rec_int|Interest received to date - Does not contribute to analysis|\n",
    "|out_prncp|Remaining outstanding principal for total amount funded - Does not contribute to analysis|\n",
    "|out_prncp_inv|Remaining outstanding principal for portion of total amount funded by investors - Does not contribute to analysis|\n",
    "|total_pymnt|Payments received to date for total amount funded - Does not contribute to analysis|\n",
    "|total_pymnt_inv|Payments received to date for portion of total amount funded by investors - Does not contribute to analysis|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loan_file.drop(columns=['member_id','emp_title','emp_length','title','last_credit_pull_d','last_pymnt_amnt','last_pymnt_d','collection_recovery_fee','earliest_cr_line','addr_state','zip_code','issue_d','funded_amnt','funded_amnt_inv','verification_status','total_rec_late_fee','total_rec_prncp','total_rec_int','out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv','url','desc'],inplace=True)\n",
    "print(loan_file.shape)\n",
    "loan_file.to_csv(\".\\\\iteration_3.csv\")\n",
    "# print(loan_file.tail(0))\n",
    "#### 3.5 Remove In-Progress Loans from Analysis ####\n",
    "Identify and remove entries which are ongoing. These will not contribute to the analysis.\n",
    "\n",
    "At the end of this exercise, the data will contain only loans which are 'Charged Off' or 'Fully Paid'.\n",
    "loan_file = loan_file[loan_file['loan_status'] != 'Current']\n",
    "loan_file.head(5)\n",
    "#### 3.6 Identify columns with empty vlaues and fill them. ####\n",
    "\n",
    "From the remaining data, identify columns which have empty cells. The next step is to identify the appropriate data to be fill the values. For this, we shall use the mode to identify and populate the values.\n",
    "print(loan_file.isna().sum() > 0)\n",
    "print(loan_file['revol_util'].mode())\n",
    "print(loan_file['pub_rec_bankruptcies'].mode())\n",
    "\n",
    "loan_file['revol_util'].fillna(loan_file['revol_util'].mode()[0],inplace=True)\n",
    "loan_file['pub_rec_bankruptcies'].fillna(loan_file['pub_rec_bankruptcies'].mode()[0])\n",
    "loan_file['term'].value_counts()\n",
    "\n",
    "loan_amnt_quantile = loan_file['loan_amnt'].quantile([0.5,0.75,0.8,.85,.9,.95,.99])\n",
    "\n",
    "print(loan_amnt_quantile)\n",
    "# 4. Visual Representation of Data #\n",
    "We have now narrowed down to 21 columns from 111 columns. The next step to commence plotting data for exploratory analysis.\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.countplot(x='loan_status',data=loan_file)\n",
    "\n",
    "total = float(len(loan_file))  # Total number of entries\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width() / 2.,\n",
    "        height + 1.0,\n",
    "        '{:.2f}%'.format((height / total) * 100),\n",
    "        ha=\"center\"\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "From the above plot, there are about 14.59% of Consumers(excluding 'In-Progress' consumers) have defaulted(i.e. 'Charged Off'). The focus would now be to identify the distribution of data for 'Charged off' consumers to identify the pattern.\n",
    "#### 4.1 : Segregating data based on analysis ####\n",
    "\n",
    "The first step is to segregate the 'Charged off' consumers to identify patterns.\n",
    "charged_off_file = loan_file[loan_file['loan_status']=='Charged Off']\n",
    "\n",
    "\n",
    "charged_off_file['term'].apply(lambda x:x.replace('36 months','36'))\n",
    "charged_off_file['term'].apply(lambda x:x.replace('60 months','60'))\n",
    "\n",
    "# print(charged_off_file.head(2))\n",
    "\n",
    "loan_file.to_csv(\".\\\\iteration_4.csv\")\n",
    "\n",
    "#### 4.2 Plot of 'Charged off' consumers vs Grade/Sub-Grade\n",
    "\n",
    "We now plot the graph of Count of 'Charged Off' consumers by Grade. \n",
    "# sns.boxplot(x='sub_grade',data=charged_off_file)\n",
    "sns.set_palette(\"viridis\")\n",
    "sns.countplot(x='grade',data=charged_off_file,order=charged_off_file['grade'].value_counts().index)\n",
    "plt.show()\n",
    "Four of the grades show substantial charge-off's by customers. We shall now analyze the sub-grades of these 4 grades to identify patterns.\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.set_palette('colorblind')\n",
    "# sns.countplot(x = 'grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'] , hue = 'sub_grade',data =charged_off_file)\n",
    "# sns.countplot(x = 'grade', order = ['B', 'C', 'D', 'E'] , hue = 'sub_grade',data =charged_off_file[charged_off_file['grade'].isin(['B','C','D','E'])])\n",
    "sns.countplot(x='sub_grade',data=charged_off_file[charged_off_file['grade'].isin(['B'])])\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x='sub_grade',data=charged_off_file[charged_off_file['grade'].isin(['C'])])\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x='sub_grade',data=charged_off_file[charged_off_file['grade'].isin(['D'])])\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x='sub_grade',data=charged_off_file[charged_off_file['grade'].isin(['E'])])\n",
    "plt.show()\n",
    "\n",
    "#### 4.3 Plot of Charge-off Consumers based on Home-ownership. ####\n",
    "\n",
    "We now plot a graph based on home-ownership.\n",
    "sns.countplot(x = 'home_ownership',data =charged_off_file, order=charged_off_file['home_ownership'].value_counts().index)\n",
    "From the table above, consumers whose have rented their homes and are paying mortgage are more likely to defaut than other category.\n",
    "#### 4.4 Plot of Charge-off Consumers based on Loan purpose. ####\n",
    "\n",
    "Below is the plot of data based on Loan purpose.\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x = 'purpose',data =charged_off_file, order=charged_off_file['purpose'].value_counts().index)\n",
    "From the above data, people, who are planning to consolidate debt are more likely to default than other category.\n",
    "#### 4.4 Plot of consumers who are deliquent for 2 years or more and who have had multiple inquiries in the last 6 months. ***\n",
    "\n",
    "The below plot shows the accounts which are deliquent for 2 years or more or consumers who have made multiple enquiries. The notion is that account which are deliquent & consumers who have made multiple enquiries are in need of additional credit due to strained financial circumstances. \n",
    "\n",
    "However, the below plot shows that greater defaults have happened due to non-deliquent consumers. Also, there does not seem to be any relationship between inquiries and 'charge-off's.\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x = 'delinq_2yrs',data =charged_off_file, order=charged_off_file['delinq_2yrs'].value_counts().index)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x = 'inq_last_6mths',data =charged_off_file, order=charged_off_file['inq_last_6mths'].value_counts().index)\n",
    "#### 4.5 Plot of Open/Total Accounts in Charge-off #####\n",
    "\n",
    "\n",
    "The plot of total number of accounts/number of open Accounts follow similar to normal curve with the peak of the charge off lying between 6 - 8 accounts.\n",
    "# print(charged_off_file.info())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.set_palette('colorblind')\n",
    "# sns.countplot(x = 'open_acc',data =charged_off_file, order=charged_off_file['open_acc'].value_counts().index)\n",
    "sns.countplot(x = 'open_acc',data =charged_off_file)\n",
    "\n",
    "\n",
    "# list_openacc = lambda x: print(x['open_acc'],x['open_acc'].value_counts())\n",
    "\n",
    "# list_openacc(charged_off_file)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.set_palette('colorblind')\n",
    "# sns.countplot(x = 'open_acc',data =charged_off_file, order=charged_off_file['open_acc'].value_counts().index)\n",
    "sns.countplot(x = 'total_acc',data =charged_off_file)\n",
    "\n",
    "#list_openacc = lambda x: print(x['total_acc'],x['total_acc'].value_counts())\n",
    "\n",
    "# list_openacc(charged_off_file)\n",
    "\n",
    "#### 4.6 Plot of Term vs Charged-off #####\n",
    "\n",
    "Shorter Terms are more likely to default than longer terms, albeit very marginally.\n",
    "# print(charged_off_file.info())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.set_palette('colorblind')\n",
    "# sns.countplot(x = 'open_acc',data =charged_off_file, order=charged_off_file['open_acc'].value_counts().index)\n",
    "sns.countplot(x = 'term',data =charged_off_file)\n",
    "# 5. Binning of continuous attributes #\n",
    "\n",
    "For the purpose of the analysis, the following attributes would need to be 'binned' as discrete distribution. For this, we are binning the following attributes - Loan Amount, Interest Rate, Annual Income, DTI.\n",
    "\n",
    "Instead of using mean/median & standard deviation, we have identified the minimum/maximum values and identify the bins.\n",
    "print(\"Loan Amount:\",charged_off_file['loan_amnt'].mean(),charged_off_file['loan_amnt'].median(),charged_off_file['loan_amnt'].max(),charged_off_file['loan_amnt'].min())\n",
    "print(\"Interest Rate:\",charged_off_file['int_rate'].max(),charged_off_file['int_rate'].min())\n",
    "print(\"Annual Income:\",charged_off_file['annual_inc'].mean(),charged_off_file['annual_inc'].median(),charged_off_file['annual_inc'].max(),charged_off_file['annual_inc'].min())\n",
    "print(\"DTI:\",charged_off_file['dti'].mean(),charged_off_file['dti'].median(),charged_off_file['dti'].max(),charged_off_file['dti'].min())\n",
    "# print(\"Total Number of Accounts:\",charged_off_file['total_acc'].median(),charged_off_file['total_acc'].max(),charged_off_file['total_acc'].min())\n",
    "\n",
    "charged_off_file['dti_bin'] = pd.cut(charged_off_file['dti'], bins=6,precision =0,labels=['0-5','5-10','10-15','15-20','20-25','>25'])\n",
    "charged_off_file['loan_amnt_bin'] = pd.cut(charged_off_file['loan_amnt'], bins=5,precision =0,labels=['0-7k','7k-14k','14k-21k','21k-28k','28k-35k'])\n",
    "charged_off_file['annual_inc_bin'] = pd.cut(charged_off_file['annual_inc'], bins=9,precision =0,labels=['0-3k','3k-8k','8k-15k','15k-25k','25k-50k','50k-75k','75k-125k','125k-250k','250k-1250k'])\n",
    "charged_off_file['total_acc_bin'] = pd.cut(charged_off_file['total_acc'], bins=8,precision =0,labels=['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80'])\n",
    "#charged_off_file['loan_amnt'] = pd.cut(charged_off_file['loan_amnt'], bins=10,precision =0,labels=['5%-9%','9%-13%','13%-17%','17%-21\n",
    "charged_off_file.to_csv(\".\\\\iteration_5.csv\")                                                                                                                                                                                        \n",
    "\n",
    "#### 5.1 Analysis of dti Data ####\n",
    "\n",
    "Based on analysis of dti bin data, dti value of 5-25 are more likely to default with dti ratio of 15-20 having max defaults.\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.set_palette('colorblind')\n",
    "# sns.countplot(x = 'open_acc',data =charged_off_file, order=charged_off_file['open_acc'].value_counts().index)\n",
    "sns.countplot(x = 'dti_bin',data =charged_off_file)\n",
    "\n",
    "\n",
    "\n",
    "#### 5.2 Analysis of Loan Amount Data ####\n",
    "\n",
    "Loan amount for charged off loans span between 900 - 35K. Analysis of loan data indicates many are smaller loan size, with more defaults happening between USD 0-7000 followed by 7K-14K and 14K-21K.\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.set_palette('colorblind')\n",
    "# sns.countplot(x = 'open_acc',data =charged_off_file, order=charged_off_file['open_acc'].value_counts().index)\n",
    "sns.countplot(x = 'loan_amnt_bin',data =charged_off_file)\n",
    "\n",
    "loan_file['dti_bin'] = pd.cut(loan_file['dti'], bins=6,precision =0,labels=['0-5','5-10','10-15','15-20','20-25','>25'])\n",
    "loan_file['loan_amnt_bin'] = pd.cut(loan_file['loan_amnt'], bins=5,precision =0,labels=['0-7k','7k-14k','14k-21k','21k-28k','28k-35k'])\n",
    "loan_file['annual_inc_bin'] = pd.cut(loan_file['annual_inc'], bins=9,precision =0,labels=['0-3k','3k-8k','8k-15k','15k-25k','25k-50k','50k-75k','75k-125k','125k-250k','250k-1250k'])\n",
    "loan_file['total_acc_bin'] = pd.cut(loan_file['total_acc'], bins=8,precision =0,labels=['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80'])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "sns.countplot(x = 'total_acc_bin',data =charged_off_file)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
